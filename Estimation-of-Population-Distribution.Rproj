Version: 1.0

RestoreWorkspace: Default
SaveWorkspace: Default
AlwaysSaveHistory: Default

EnableCodeIndexing: Yes
UseSpacesForTab: Yes
NumSpacesForTab: 2
Encoding: UTF-8

RnwWeave: Sweave
LaTeX: pdfLaTeX

###############################################################################################################################
#####CODE:

library(SPARQL)
library(ggplot2)

#############################################################################################  
# input the query editor

endpoint <- "http://dbpedia.org/sparql"

#############################################################################################
# construct SPARQL query to select the data from dbpedia

query<-'
prefix      dbpedia: <http://dbpedia.org/resource/> 
prefix  dbpedia-owl: <http://dbpedia.org/ontology/> 

SELECT DISTINCT  ?place 
                 ?latitude 
                 ?longitude 
                 ?population 
  WHERE 
    {
      ?place          dbpedia-owl:country  <http://dbpedia.org/resource/Greece> .
      ?place  dbpedia-owl:populationTotal  ?population                                  .
      ?place                      geo:lat  ?latitude                                    .
      ?place                     geo:long  ?longitude                                   .
    } 
  ORDER BY ?place 
' 

q100<-SPARQL(endpoint, query)
q100<- q100$results
q100
summary(q100$population)

ggplot(data = q100, aes(x=place, y=population)) + theme_bw() + geom_bar(stat="identity") + 
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) + 
  ggtitle("Population of Greek Regions using data from DBpedia ") 
+ labs(x="Council Area", y="Rate per 100,000 people") + 
  theme(legend.position=
          "none")

####################################################################################################
# Apply machine learning algorithm - Classification and Regression trees######

library(tree)
library(ISLR)
attach(q100)
str(q100)
High=ifelse(q100$population<=100000,"No","Yes") #120-0.69-0.169
q100=data.frame(q100,High)
head(q100)
sort(High)
tree.q100=tree(High~.-population,q100)
summary(tree.q100)
tree.q100

par(mar=c(3,1,3,1))
plot(tree.q100)
text(tree.q100,pretty=0,cex=0.5)

###########################################################################################
### Classification tree (GREECE)

####Create the test sample and apply the tree model on this 
set.seed(2)
train=sample(1:nrow(q100),68) 
q100.test=q100[-train,]
High.test=High[-train]

tree.q100=tree(High~.-population,q100,subset=train)
tree.pred=predict(tree.q100,q100.test,type="class")
xtab1<-table(tree.pred,High.test)
xtab1
(31+18)/(31+18+11+8)   ## 0.7206

#### tree pruning (cross validation for determining the optimal level of tree complexity)
set.seed(3)
cv.q100=cv.tree(tree.q100,FUN=prune.misclass)
names(cv.q100)


#### error rate and complexity cost in relation to tree size
plot(cv.q100$size ,cv.q100$dev ,type="b",ylab = "cross-validation error rate", xlab = "size")

plot(cv.q100$k ,cv.q100$dev ,type="b",ylab = "cost-complexity parameter k", xlab = "size")

### search the appropriate tree
cv.q100

### Tree pruning (Choose to prune the tree into three junctions)
prune.q100=prune.misclass(tree.q100,best=5)
plot(prune.q100)
text(prune.q100,pretty=0,cex=0.85)

### Pruning tree validation
tree.pred=predict(prune.q100,q100.test,type="class")
xtab2<-table(tree.pred,High.test)
xtab2
(29+19)/(29+19+13+7)      ## 0.7059

##############################################################################################################
### Regression tree (GREECE)

#tree constructiong
set.seed (1)
train = sample (1: nrow(q100), nrow(q100)/2)

tree.boston =tree(population~.,q100 ,subset =train)
summary (tree.boston )

plot(tree.boston)
text(tree.boston ,pretty =0,cex=0.85)

#pruning
cv.boston =cv.tree(tree.boston )
cv.boston

cvtable<-cbind(cv.boston$size,cv.boston$dev)
colnames(cvtable)<-c('size','deviance')
cvtable
min(cvtable[,2])

min(cvtable[,2])
plot(cv.boston$size ,cv.boston$dev ,type='b')

prune.boston =prune.tree(tree.boston ,best =3)
summary(prune.boston )
plot(prune.boston )
text(prune.boston ,pretty =0,cex=0.85)


#### Prediction for training set
yhat=predict(tree.boston ,newdata =q100[-train,])
boston.test=q100[-train ,"population"]
plot(yhat ,boston.test)
abline (0,1)

# Mean square error
library(Metrics)
mse(yhat,boston.test)
mean((yhat -boston.test)^2)



